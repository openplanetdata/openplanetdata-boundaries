name: Extract Boundary (Reusable)

on:
  workflow_call:
    inputs:
      entity_code:
        description: 'Code for the entity (e.g., FR for France, africa for Africa)'
        required: true
        type: string
      entity_name:
        description: 'Human-readable name of the entity'
        required: true
        type: string
      entity_type:
        description: 'Type of entity (country, continent, region, etc.)'
        required: true
        type: string
      osm_query:
        description: 'OSM query to find the boundary relation (e.g., a["ISO3166-1:alpha2"="FR"])'
        required: true
        type: string
      remote_path:
        description: 'Remote path for upload (e.g., /osm/boundaries/countries)'
        required: true
        type: string
      remote_version:
        description: 'Remote version number'
        required: false
        type: string
        default: '1'
      tags:
        description: 'Newline-separated tags for metadata'
        required: false
        type: string
        default: |
          boundary
          openstreetmap
          public
      cleanup_planet_files:
        description: 'Whether to cleanup planet files after processing (set to false to reuse across multiple countries)'
        required: false
        type: boolean
        default: false
      has_coastline:
        description: 'Whether this entity has a coastline (false for landlocked countries)'
        required: false
        type: boolean
        default: true

    outputs:
      failure_reason:
        description: 'Reason for failure if extraction failed'
        value: ${{ jobs.extract.outputs.failure_reason }}
      feature_count:
        description: 'Number of features in the output'
        value: ${{ jobs.extract.outputs.feature_count }}
      output_file:
        description: 'Path to the generated GeoJSON file'
        value: ${{ jobs.extract.outputs.output_file }}
      geopackage_file:
        description: 'Path to the generated GeoPackage file'
        value: ${{ jobs.extract.outputs.geopackage_file }}
      parquet_file:
        description: 'Path to the generated GeoParquet file'
        value: ${{ jobs.extract.outputs.parquet_file }}
      success:
        description: 'Whether the extraction succeeded (true/false)'
        value: ${{ jobs.extract.outputs.success }}

    secrets:
      R2INDEX_API_URL:
        description: 'R2Index API URL'
        required: true
      R2INDEX_API_TOKEN:
        description: 'R2Index API token'
        required: true
      R2_ACCESS_KEY_ID:
        description: 'R2 access key ID'
        required: true
      R2_SECRET_ACCESS_KEY:
        description: 'R2 secret access key'
        required: true
      R2_ENDPOINT_URL:
        description: 'R2 endpoint URL'
        required: true
      R2_BUCKET:
        description: 'R2 bucket name'
        required: true

jobs:
  extract:
    runs-on: self-hosted
    timeout-minutes: 60

    outputs:
      failure_reason: ${{ steps.extract.outputs.failure_reason }}
      feature_count: ${{ steps.extract.outputs.feature_count }}
      output_file: ${{ steps.extract.outputs.output_file }}
      geopackage_file: ${{ steps.extract.outputs.geopackage_file }}
      parquet_file: ${{ steps.extract.outputs.parquet_file }}
      success: ${{ steps.extract.outputs.success }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          clean: false

      - name: Set date tag
        id: date
        uses: openplanetdata/actions/set-date-tag@main

        - name: Install GOL
          uses: openplanetdata/actions/install-gol@main
          with:
            github_token: ${{ secrets.GITHUB_TOKEN }}
            version: 2

      - name: Install system dependencies
        shell: bash
        run: |
          need_install() { ! command -v "$1" &>/dev/null; }

          # Detect OS and package manager
          if command -v apt-get &>/dev/null; then
            # Ubuntu/Debian
            PKG_MANAGER="apt-get"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal-bin)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo apt-get update -qq
              sudo apt-get install -y "${PKGS[@]}"
            fi
          elif command -v dnf &>/dev/null; then
            # Fedora/RHEL/CentOS
            PKG_MANAGER="dnf"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo dnf -y install "${PKGS[@]}"
            fi
          else
            echo "⚠️ Unsupported package manager. Please install manually: gdal, jq"
            exit 1
          fi

          # Verify installations
          echo "Verifying installations..."
          command -v gol && gol --version
          command -v ogr2ogr && ogr2ogr --version
          command -v jq && jq --version

      - name: Install Python dependencies
        shell: bash
        run: |
          python3 -m pip install --user pyproj elaunira-r2index

      - name: Download planet GOL
        uses: openplanetdata/actions/download@main
        with:
          remote_path: /osm/planet/gol/v2/planet-latest.osm.gol

      - name: Download coastline GPKG
        uses: openplanetdata/actions/download@main
        with:
          remote_path: /boundaries/coastline/geopackage/v1/planet-latest.coastline.gpkg

      - name: Extract boundary
        id: extract
        shell: bash
        run: |
          set +e  # Don't exit on error, we'll handle it

          # Allow handling large GeoJSON objects
          export OGR_GEOJSON_MAX_OBJ_SIZE="${OGR_GEOJSON_MAX_OBJ_SIZE:-0}"

          ENTITY_TYPE="${{ inputs.entity_type }}"
          ENTITY_CODE="${{ inputs.entity_code }}"
          ENTITY_NAME="${{ inputs.entity_name }}"
          OSM_QUERY='${{ inputs.osm_query }}'

          PLANET_GOL="planet-latest.osm.gol"
          COASTLINE_DB="planet-latest.coastline.gpkg"
          case "$ENTITY_TYPE" in
            country) OUTPUT_DIR="boundaries/countries" ;;
            continent) OUTPUT_DIR="boundaries/continents" ;;
            *) OUTPUT_DIR="boundaries/${ENTITY_TYPE}s" ;;
          esac
          OUTPUT_FILE="${ENTITY_CODE}.boundary.geojson"
          TMPDIR="boundaries/tmp/${ENTITY_CODE}"
          LOGFILE="boundaries/logs/${ENTITY_CODE}.log"

          # Create directories
          mkdir -p "$OUTPUT_DIR" "$TMPDIR" "boundaries/logs"

          # Redirect output to log
          exec 1> >(tee -a "$LOGFILE")
          exec 2>&1

          echo "=========================================="
          echo "Extracting: $ENTITY_CODE - $ENTITY_NAME"
          echo "Type: $ENTITY_TYPE"
          echo "Query: $OSM_QUERY"
          echo "Started at: $(date -u +%Y-%m-%d_%H:%M:%S)"
          echo "=========================================="

          # Step 1: Extract boundary using gol query
          echo "→ Step 1/5: Extracting boundary with gol query..."
          if ! gol query "$PLANET_GOL" "$OSM_QUERY" -f geojson > "$TMPDIR/${ENTITY_CODE}_raw.geojson"; then
            echo "::error::${ENTITY_CODE}: failed to extract boundary with gol query" >&2
            echo "❌ Failed to extract boundary with gol query" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to extract boundary with gol query" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 0
          fi

          # Validate raw extraction
          FEATURE_COUNT=$(jq '.features | length' "$TMPDIR/${ENTITY_CODE}_raw.geojson" 2>/dev/null || echo "0")
          if [ "$FEATURE_COUNT" -eq 0 ]; then
            echo "::error::${ENTITY_CODE}: no features found in gol query result" >&2
            echo "❌ No features found in gol query result" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=No features found in gol query result" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 0
          fi
          echo "  ✓ Extracted boundary with $FEATURE_COUNT feature(s)"

          # Step 2: Clip with coastline if coastal entity
          HAS_COASTLINE="${{ inputs.has_coastline }}"
          CLIPPED=false

          if [ "$HAS_COASTLINE" = "true" ]; then
            echo "→ Step 2/5: Clipping with coastline data..."
            if ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_clipped.geojson" "$COASTLINE_DB" land_polygons \
              -clipsrc "$TMPDIR/${ENTITY_CODE}_raw.geojson" -q 2>/dev/null; then
              echo "  ✓ Clipped with coastline data"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_clipped.geojson"
              CLIPPED=true
            else
              echo "  ⚠️ Coastline clipping failed, using raw boundary"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
            fi
          else
            echo "→ Step 2/5: Skipping coastline clipping (landlocked)"
            WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
          fi

          # Step 3: Dissolve geometry (only if clipped with coastline)
          if [ "$CLIPPED" = "true" ]; then
            echo "→ Step 3/5: Dissolving geometry..."
            if ! ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" "$WORKING_FILE" -dialect sqlite \
              -sql "SELECT ST_CollectionExtract(ST_UnaryUnion(ST_Collect(geometry)), 3) AS geometry FROM land_polygons" -q; then
              echo "❌ Failed to dissolve geometry" >&2
              echo "success=false" >> $GITHUB_OUTPUT
              echo "failure_reason=Failed to dissolve geometry" >> $GITHUB_OUTPUT
              rm -rf "$TMPDIR"
              exit 3
            fi
            echo "  ✓ Dissolved geometry"
            FINAL_FILE="$TMPDIR/${ENTITY_CODE}_dissolved.geojson"
          else
            echo "→ Step 3/5: Skipping dissolve (no clipping performed)"
            FINAL_FILE="$WORKING_FILE"
          fi

          # Step 4: Copy to final output
          echo "→ Step 4/5: Creating final output..."
          cp "$FINAL_FILE" "$OUTPUT_DIR/$OUTPUT_FILE"
          echo "  ✓ Created final output"

          # Step 5: Compute and add area property
          echo "→ Step 5/5: Computing area..."
          if ! AREA_KM2=$(python3 scripts/compute-area.py "$OUTPUT_DIR/$OUTPUT_FILE"); then
            echo "❌ Failed to compute area" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to compute area" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            rm -rf "$TMPDIR"
            exit 6
          fi
          echo "  ✓ Computed area: ${AREA_KM2} km²"

          # Add properties (area, name, and entity code)
          ENTITY_TYPE="${{ inputs.entity_type }}"
          ENTITY_CODE="${{ inputs.entity_code }}"
          ENTITY_NAME="${{ inputs.entity_name }}"
          TARGET_LAYER="boundary"

          if [ "$ENTITY_TYPE" = "country" ]; then
            # For countries, add ISO3166-1:alpha2 code and name
            CODE_UPPER=$(echo "$ENTITY_CODE" | tr '[:lower:]' '[:upper:]')
            TARGET_LAYER="$CODE_UPPER"
            jq --arg area "$AREA_KM2" --arg iso_code "$CODE_UPPER" --arg name "$ENTITY_NAME" \
              '.features[0].properties.area = ($area | tonumber) | .features[0].properties."ISO3166-1:alpha2" = $iso_code | .features[0].properties.name = $name' \
              "$OUTPUT_DIR/$OUTPUT_FILE" > "$OUTPUT_DIR/$OUTPUT_FILE.tmp"
          elif [ "$ENTITY_TYPE" = "continent" ]; then
            # For continents, add continent code and name
            CODE_UPPER=$(echo "$ENTITY_CODE" | tr '[:lower:]' '[:upper:]')
            jq --arg area "$AREA_KM2" --arg code "$CODE_UPPER" --arg name "$ENTITY_NAME" \
              '.features[0].properties.area = ($area | tonumber) | .features[0].properties.code = $code | .features[0].properties.name = $name' \
              "$OUTPUT_DIR/$OUTPUT_FILE" > "$OUTPUT_DIR/$OUTPUT_FILE.tmp"
          else
            # For other entity types, add area and name
            jq --arg area "$AREA_KM2" --arg name "$ENTITY_NAME" \
              '.features[0].properties.area = ($area | tonumber) | .features[0].properties.name = $name' \
              "$OUTPUT_DIR/$OUTPUT_FILE" > "$OUTPUT_DIR/$OUTPUT_FILE.tmp"
          fi

          mv "$OUTPUT_DIR/$OUTPUT_FILE.tmp" "$OUTPUT_DIR/$OUTPUT_FILE"
          echo "  ✓ Added properties to output"

          if [ "$ENTITY_TYPE" = "country" ]; then
            TMP_LAYER_FILE="$OUTPUT_DIR/${ENTITY_CODE}.layer.geojson"
            if ogr2ogr --config OGR_GEOJSON_MAX_OBJ_SIZE 0 -f GeoJSON "$TMP_LAYER_FILE" "$OUTPUT_DIR/$OUTPUT_FILE" \
              -nln "$TARGET_LAYER"; then
              mv "$TMP_LAYER_FILE" "$OUTPUT_DIR/$OUTPUT_FILE"
              echo "  ✓ Set GeoJSON layer name to $TARGET_LAYER"
            else
              echo "  ⚠ Failed to set GeoJSON layer name to $TARGET_LAYER (keeping default)" >&2
              rm -f "$TMP_LAYER_FILE"
            fi
          fi

          # Validate the output
          echo "→ Validating output..."
          if [ ! -f "$OUTPUT_DIR/$OUTPUT_FILE" ]; then
            echo "❌ Output file not created" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Output file not created" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 4
          fi

          FINAL_FEATURE_COUNT=$(jq '.features | length' "$OUTPUT_DIR/$OUTPUT_FILE" 2>/dev/null || echo "0")
          if [ "$FINAL_FEATURE_COUNT" -eq 0 ]; then
            echo "❌ No features in final output" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=No features in output" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            rm -rf "$TMPDIR"
            exit 5
          fi
          echo "  ✓ Output validated: $FINAL_FEATURE_COUNT feature(s)"

          # Clean up temp files
          rm -rf "$TMPDIR"

          # Convert GeoJSON to GeoPackage
          echo "→ Converting to GeoPackage..."
          GPKG_FILE="${OUTPUT_DIR}/${ENTITY_CODE}.boundary.gpkg"
          if ! ogr2ogr --config OGR_GEOJSON_MAX_OBJ_SIZE 0 -f GPKG "$GPKG_FILE" "$OUTPUT_DIR/$OUTPUT_FILE" \
            -nln "$TARGET_LAYER" -overwrite; then
            echo "❌ Failed to convert to GeoPackage" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to convert to GeoPackage" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            exit 7
          fi
          echo "  ✓ GeoPackage created: $(basename "$GPKG_FILE")"

          # Convert GeoJSON to GeoParquet
          echo "→ Converting to GeoParquet..."
          PARQUET_FILE="${OUTPUT_DIR}/${ENTITY_CODE}.boundary.parquet"
          if ! ogr2ogr -f Parquet "$PARQUET_FILE" "$OUTPUT_DIR/$OUTPUT_FILE" \
            --config OGR_GEOJSON_MAX_OBJ_SIZE 0 \
            -lco COMPRESSION=ZSTD \
            -lco GEOMETRY_ENCODING=GEOARROW \
            -lco ROW_GROUP_SIZE=65536 \
            -nln "$TARGET_LAYER"; then
            echo "❌ Failed to convert to GeoParquet" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to convert to GeoParquet" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            rm -f "$GPKG_FILE"
            exit 8
          fi
          echo "  ✓ GeoParquet created: $(basename $PARQUET_FILE)"

          echo "→ Converting GeoJSON output to single feature..."
          if ! python3 scripts/normalize-single-feature.py "$OUTPUT_DIR/$OUTPUT_FILE"; then
            echo "❌ Failed to convert GeoJSON to single feature" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to normalize GeoJSON to single feature" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            rm -f "$GPKG_FILE"
            rm -f "$PARQUET_FILE"
            exit 9
          fi
          echo "  ✓ GeoJSON normalized to single feature"

          ls -alh .

          # Set outputs
          echo "success=true" >> $GITHUB_OUTPUT
          echo "output_file=$OUTPUT_DIR/$OUTPUT_FILE" >> $GITHUB_OUTPUT
          echo "geopackage_file=$GPKG_FILE" >> $GITHUB_OUTPUT
          echo "parquet_file=$PARQUET_FILE" >> $GITHUB_OUTPUT
          echo "feature_count=$FINAL_FEATURE_COUNT" >> $GITHUB_OUTPUT

          echo "✅ $OUTPUT_FILE created successfully with $FINAL_FEATURE_COUNT feature(s)"
          echo "✅ $(basename "$GPKG_FILE") created successfully"
          echo "✅ $(basename $PARQUET_FILE) created successfully"
          echo "Finished at: $(date -u +%Y-%m-%d_%H:%M:%S)"

      - name: Upload all formats to R2 and register
        if: steps.extract.outputs.success == 'true'
        env:
          R2INDEX_API_URL: ${{ secrets.R2INDEX_API_URL }}
          R2INDEX_API_TOKEN: ${{ secrets.R2INDEX_API_TOKEN }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        shell: bash
        run: |
          python3 << 'UPLOAD_SCRIPT'
          import os
          from elaunira.r2index import R2Config, R2IndexClient

          # Configuration from inputs
          entity_code = "${{ inputs.entity_code }}"
          entity_type = "${{ inputs.entity_type }}"
          remote_path = "${{ inputs.remote_path }}"
          remote_version = "${{ inputs.remote_version }}"
          tags = """${{ inputs.tags }}""".strip().split('\n')
          tags = [t.strip() for t in tags if t.strip()]

          # File paths from extraction
          geojson_file = "${{ steps.extract.outputs.output_file }}"
          gpkg_file = "${{ steps.extract.outputs.geopackage_file }}"
          parquet_file = "${{ steps.extract.outputs.parquet_file }}"

          # Initialize client
          r2_config = R2Config(
              access_key_id=os.environ["R2_ACCESS_KEY_ID"],
              secret_access_key=os.environ["R2_SECRET_ACCESS_KEY"],
              endpoint_url=os.environ["R2_ENDPOINT_URL"],
              bucket=os.environ["R2_BUCKET"],
          )

          client = R2IndexClient(
              api_url=os.environ["R2INDEX_API_URL"],
              api_token=os.environ["R2INDEX_API_TOKEN"],
              r2_config=r2_config,
          )

          category = "coastline" if entity_type == "coastline" else "boundary"

          # Upload GeoPackage
          if gpkg_file and os.path.exists(gpkg_file):
              print(f"Uploading GeoPackage: {gpkg_file}")
              record = client.upload_and_register(
                  file_path=gpkg_file,
                  category=category,
                  entity=entity_code,
                  remote_path=f"{remote_path}/{entity_code}/geopackage",
                  remote_filename=f"{entity_code}-latest.boundary.gpkg",
                  remote_version=remote_version,
                  tags=tags + ["geopackage"],
              )
              print(f"  Registered: {record.id}")

          # Upload GeoJSON
          if geojson_file and os.path.exists(geojson_file):
              print(f"Uploading GeoJSON: {geojson_file}")
              record = client.upload_and_register(
                  file_path=geojson_file,
                  category=category,
                  entity=entity_code,
                  remote_path=f"{remote_path}/{entity_code}/geojson",
                  remote_filename=f"{entity_code}-latest.boundary.geojson",
                  remote_version=remote_version,
                  tags=tags + ["geojson"],
              )
              print(f"  Registered: {record.id}")

          # Upload GeoParquet
          if parquet_file and os.path.exists(parquet_file):
              print(f"Uploading GeoParquet: {parquet_file}")
              record = client.upload_and_register(
                  file_path=parquet_file,
                  category=category,
                  entity=entity_code,
                  remote_path=f"{remote_path}/{entity_code}/geoparquet",
                  remote_filename=f"{entity_code}-latest.boundary.parquet",
                  remote_version=remote_version,
                  tags=tags + ["geoparquet"],
              )
              print(f"  Registered: {record.id}")

          client.close()
          print("All files uploaded and registered successfully")
          UPLOAD_SCRIPT

      - name: Cleanup generated files
        if: always()
        run: |
          # Always cleanup metadata and temp files
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.geojson.{sha256,metadata}
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.gpkg.{sha256,metadata}
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.parquet.{sha256,metadata}
          rm -rf boundaries/tmp boundaries/logs
